{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JKourelis/BUSCO-Colab/blob/main/BUSCO_ProteomeQualityAssessment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuVH-7yyNzyt",
        "outputId": "641a04b1-fdb7-44d5-fb7b-49257d7bd30e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
            "‚ïë           BUSCO Proteome Analysis Notebook                ‚ïë\n",
            "‚ïë                    Ready to Start                          ‚ïë\n",
            "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
            "\n",
            "üìã Follow the cells in order:\n",
            "   1. Connect to Google Drive\n",
            "   2. Install BUSCO and dependencies\n",
            "   3. Select your lineage dataset\n",
            "   4. Upload your proteome file\n",
            "   5. Run BUSCO analysis\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# @title **BUSCO v6 Proteome Quality Assessment**\n",
        "# @markdown ---\n",
        "# @markdown ### üß¨ **Benchmarking Universal Single-Copy Orthologs**\n",
        "# @markdown\n",
        "# @markdown This notebook runs **BUSCO v6.0.0** analysis on proteome (protein) FASTA files to assess completeness and quality based on evolutionarily-informed expectations of gene content.\n",
        "# @markdown\n",
        "# @markdown **What BUSCO Does:**\n",
        "# @markdown - Identifies single-copy ortholog genes expected in your lineage\n",
        "# @markdown - Calculates completeness metrics (Complete, Fragmented, Missing)\n",
        "# @markdown - Validates genome assembly or gene prediction quality\n",
        "# @markdown\n",
        "# @markdown **Required Input:**\n",
        "# @markdown - Proteome file in FASTA format (.faa, .fasta, .fa)\n",
        "# @markdown - Selection of appropriate lineage dataset (odb12 recommended)\n",
        "# @markdown\n",
        "# @markdown **Expected Runtime:** 1-30 minutes depending on proteome size and runtime selection\n",
        "# @markdown\n",
        "# @markdown ---\n",
        "# @markdown\n",
        "# @markdown ### ‚ö° **IMPORTANT: Runtime Selection for Best Performance**\n",
        "# @markdown\n",
        "# @markdown Before running this notebook, select **TPU runtime** for maximum speed:\n",
        "# @markdown 1. Go to **Runtime ‚Üí Change runtime type**\n",
        "# @markdown 2. Set **Hardware accelerator** to **TPU v5e-1** or **TPU v6e-1**\n",
        "# @markdown 3. This gives you **24-44 CPU threads** instead of 2\n",
        "# @markdown\n",
        "# @markdown **Performance comparison:**\n",
        "# @markdown - **Standard GPU/CPU runtime**: 2 threads ‚Üí 30-60 min for large proteomes\n",
        "# @markdown - **TPU v5e-1 runtime**: 24 threads ‚Üí 5-10 min for large proteomes (12x faster)\n",
        "# @markdown - **TPU v6e-1 runtime**: 44 threads ‚Üí 3-8 min for large proteomes (22x faster)\n",
        "# @markdown\n",
        "# @markdown **Note:** You're using the TPU's CPU host for computation, not the TPU cores themselves. BUSCO is CPU-intensive (HMMER/gene prediction), so TPU runtime is optimal.\n",
        "# @markdown\n",
        "# @markdown ---\n",
        "# @markdown\n",
        "# @markdown üìö **Documentation:** [BUSCO Official Site](https://busco.ezlab.org/) | üìÑ **Paper:** [Manni et al. 2021](https://doi.org/10.1093/molbev/msab199)\n",
        "# @markdown\n",
        "# @markdown ---\n",
        "\n",
        "print(\"‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\")\n",
        "print(\"‚ïë           BUSCO v6 Proteome Analysis Notebook            ‚ïë\")\n",
        "print(\"‚ïë           Using OrthoDB v12 Datasets (odb12)             ‚ïë\")\n",
        "print(\"‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\")\n",
        "print(\"\\n‚ö° PERFORMANCE TIP:\")\n",
        "print(\"   For best results, use TPU runtime:\")\n",
        "print(\"   ‚Ä¢ TPU v5e-1: 24 threads (12x faster)\")\n",
        "print(\"   ‚Ä¢ TPU v6e-1: 44 threads (22x faster)\")\n",
        "print(\"   Runtime ‚Üí Change runtime type ‚Üí TPU v5e-1 or v6e-1\")\n",
        "print(\"   Standard GPU/CPU runtime only provides 2 threads\\n\")\n",
        "print(\"üìã Follow the cells in order:\")\n",
        "print(\"   1. Setup Conda & Restart Kernel\")\n",
        "print(\"   2. Install BUSCO v6 and dependencies\")\n",
        "print(\"   3. Upload your proteome file\")\n",
        "print(\"   4. Browse available lineage datasets\")\n",
        "print(\"   5. Download your chosen lineage\")\n",
        "print(\"   6. Run BUSCO analysis\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvhZ0rdPOIyV",
        "outputId": "3b15e5da-4c3f-44bf-8021-9e0f0710e82b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "‚úÖ Google Drive connected successfully!\n",
            "üìÅ Drive mounted at: /content/drive/MyDrive/\n",
            "üìÇ Results will be saved to: /content/drive/MyDrive/BUSCO_Results\n"
          ]
        }
      ],
      "source": [
        "# @title **Connect to Google Drive** { display-mode: \"form\" }\n",
        "# @markdown Mount your Google Drive to access files and save results.\n",
        "\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "try:\n",
        "    drive.mount('/content/drive', force_remount=False)\n",
        "    print(\"‚úÖ Google Drive connected successfully!\")\n",
        "    print(f\"üìÅ Drive mounted at: /content/drive/MyDrive/\")\n",
        "\n",
        "    # Create BUSCO results directory if it doesn't exist\n",
        "    results_dir = \"/content/drive/MyDrive/BUSCO_Results\"\n",
        "    os.makedirs(results_dir, exist_ok=True)\n",
        "    print(f\"üìÇ Results will be saved to: {results_dir}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error mounting Google Drive: {e}\")\n",
        "    print(\"Please authorize access when prompted and try again.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XonDym-cOROP",
        "outputId": "e5d52f31-e8fa-4016-ee19-5526f883ac75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîß Installing Conda environment for the first time...\n",
            "\n",
            "‚úÖ Condacolab installed.\n",
            "‚ö†Ô∏è The kernel will now restart automatically to activate the environment.\n",
            "   This is normal. After the restart, please run Cell 2.\n",
            "‚è¨ Downloading https://github.com/jaimergp/miniforge/releases/download/24.11.2-1_colab/Miniforge3-colab-24.11.2-1_colab-Linux-x86_64.sh...\n",
            "üì¶ Installing...\n",
            "üìå Adjusting configuration...\n",
            "ü©π Patching environment...\n",
            "‚è≤ Done in 0:00:06\n",
            "üîÅ Restarting kernel...\n"
          ]
        }
      ],
      "source": [
        "# @title Setup Conda & Restart Kernel\n",
        "# @markdown Run this cell first to install the Mamba/Conda environment.\n",
        "# @markdown The kernel will restart automatically (~1 minute).\n",
        "# @markdown After the restart, proceed to Cell 2.\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "# Check if condacolab is already installed to avoid re-running on a prepped machine\n",
        "try:\n",
        "    import condacolab\n",
        "    print(\"‚úÖ Condacolab is already installed and the environment is ready.\")\n",
        "    print(\"\\n‚û°Ô∏è Proceed to Cell 2 to install BUSCO.\")\n",
        "except ImportError:\n",
        "    print(\"üîß Installing Conda environment for the first time...\")\n",
        "\n",
        "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"condacolab\"], check=True)\n",
        "    import condacolab\n",
        "\n",
        "    print(\"\\n‚úÖ Condacolab installed.\")\n",
        "    print(\"‚ö†Ô∏è The kernel will now restart automatically to activate the environment.\")\n",
        "    print(\"   This is normal. After the restart, please run Cell 2.\")\n",
        "\n",
        "    condacolab.install()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MITQSsbNXThi",
        "outputId": "b224925b-d13b-4e9b-ec37-d9c0d17b71b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "STEP 1: Cleaning up previous installation attempts...\n",
            "======================================================================\n",
            "‚úÖ Previous environments removed.\n",
            "\n",
            "======================================================================\n",
            "STEP 2: Installing BUSCO v6...\n",
            "======================================================================\n",
            "‚è≥ This will take 3-5 minutes...\n",
            "\n",
            "üî© Running command: mamba create -n busco -y -c conda-forge -c bioconda \"python=3.11\" \"busco=6.0.0\"\n",
            "\n",
            "Transaction\n",
            "\n",
            "  Prefix: /usr/local/envs/busco\n",
            "\n",
            "  Updating specs:\n",
            "\n",
            "   - python=3.11\n",
            "   - busco=6.0.0\n",
            "\n",
            "\n",
            "  Package                             Version  Build                 Channel           Size\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "  Install:\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "\n",
            "  + font-ttf-dejavu-sans-mono            2.37  hab24e00_0            conda-forge      397kB\n",
            "  + python_abi                           3.11  8_cp311               conda-forge        7kB\n",
            "  + font-ttf-inconsolata                3.000  h77eed37_0            conda-forge       97kB\n",
            "  + font-ttf-source-code-pro            2.038  h77eed37_0            conda-forge      701kB\n",
            "  + font-ttf-ubuntu                      0.83  h77eed37_3            conda-forge        2MB\n",
            "  + tzdata                              2025b  h78e105d_0            conda-forge      123kB\n",
            "  + ca-certificates                 2025.10.5  hbd8a1cb_0            conda-forge      156kB\n",
            "  + _x86_64-microarch-level                 3  2_x86_64_v3           conda-forge        8kB\n",
            "  + fonts-conda-forge                       1  0                     conda-forge        4kB\n",
            "  + fonts-conda-ecosystem                   1  0                     conda-forge        4kB\n",
            "  + libgomp                            15.2.0  h767d61c_7            conda-forge      448kB\n",
            "  + libboost-headers                   1.85.0  ha770c72_4            conda-forge       14MB\n",
            "  + _libgcc_mutex                         0.1  conda_forge           conda-forge     Cached\n",
            "  + mpi                                   1.0  openmpi               conda-forge        4kB\n",
            "  + ld_impl_linux-64                     2.44  ha97dd6f_2            conda-forge      747kB\n",
            "  + _openmp_mutex                         4.5  2_gnu                 conda-forge     Cached\n",
            "  + libgcc                             15.2.0  h767d61c_7            conda-forge      823kB\n",
            "  + libbrotlicommon                     1.1.0  hb03c661_4            conda-forge       69kB\n",
            "  + keyutils                            1.6.3  hb9d3cd8_0            conda-forge      134kB\n",
            "  + xorg-libxau                        1.0.12  hb9d3cd8_0            conda-forge       15kB\n",
            "  + xorg-libxdmcp                       1.1.5  hb9d3cd8_0            conda-forge       20kB\n",
            "  + pthread-stubs                         0.4  hb9d3cd8_1002         conda-forge        8kB\n",
            "  + libwebp-base                        1.6.0  hd42ef1d_0            conda-forge      429kB\n",
            "  + libgfortran5                       15.2.0  hcd61629_7            conda-forge        2MB\n",
            "  + libnsl                              2.0.1  hb9d3cd8_1            conda-forge       34kB\n",
            "  + libffi                              3.4.6  h2dba641_1            conda-forge       57kB\n",
            "  + libiconv                             1.18  h3b78370_2            conda-forge      790kB\n",
            "  + xorg-libice                         1.1.2  hb9d3cd8_0            conda-forge       59kB\n",
            "  + libdeflate                           1.24  h86f0d12_0            conda-forge       73kB\n",
            "  + c-ares                             1.34.5  hb9d3cd8_0            conda-forge      207kB\n",
            "  + libjpeg-turbo                       3.1.0  hb9d3cd8_0            conda-forge      629kB\n",
            "  + alsa-lib                           1.2.14  hb9d3cd8_0            conda-forge      567kB\n",
            "  + ncurses                               6.5  h2d0b736_3            conda-forge      892kB\n",
            "  + liblzma                             5.8.1  hb9d3cd8_2            conda-forge      113kB\n",
            "  + bzip2                               1.0.8  hda65f42_8            conda-forge      260kB\n",
            "  + libzlib                             1.3.1  hb9d3cd8_2            conda-forge     Cached\n",
            "  + libstdcxx                          15.2.0  h8f9b012_7            conda-forge        4MB\n",
            "  + libgcc-ng                          15.2.0  h69a702a_7            conda-forge       29kB\n",
            "  + openssl                             3.5.4  h26f9b46_0            conda-forge        3MB\n",
            "  + libuuid                            2.41.2  he9a06e4_0            conda-forge       37kB\n",
            "  + libexpat                            2.7.1  hecca717_0            conda-forge       75kB\n",
            "  + libbrotlienc                        1.1.0  hb03c661_4            conda-forge      290kB\n",
            "  + libbrotlidec                        1.1.0  hb03c661_4            conda-forge       33kB\n",
            "  + libxcb                             1.17.0  h8a09558_0            conda-forge      396kB\n",
            "  + libgfortran                        15.2.0  h69a702a_7            conda-forge       29kB\n",
            "  + libgettextpo                       0.25.1  h3f43e3d_1            conda-forge      188kB\n",
            "  + tar                                  1.35  h3b78370_0            conda-forge      779kB\n",
            "  + libedit                      3.1.20250104  pl5321h7949ede_0      conda-forge      135kB\n",
            "  + readline                              8.2  h8c095d6_2            conda-forge      282kB\n",
            "  + xz-tools                            5.8.1  hb9d3cd8_2            conda-forge       96kB\n",
            "  + xz-gpl-tools                        5.8.1  hbcc6ac9_2            conda-forge       34kB\n",
            "  + liblzma-devel                       5.8.1  hb9d3cd8_2            conda-forge      440kB\n",
            "  + libsqlite                          3.50.4  h0c1763c_0            conda-forge      933kB\n",
            "  + pcre2                               10.46  h1321c63_0            conda-forge        1MB\n",
            "  + tk                                 8.6.13  noxft_hd72426e_102    conda-forge        3MB\n",
            "  + libpng                             1.6.50  h421ea60_1            conda-forge      317kB\n",
            "  + zlib                                1.3.1  hb9d3cd8_2            conda-forge       92kB\n",
            "  + metis                               5.1.0  hd0bcaf9_1007         conda-forge        4MB\n",
            "  + lerc                                4.0.0  h0aef613_1            conda-forge      264kB\n",
            "  + pixman                             0.46.4  h54a6638_1            conda-forge      451kB\n",
            "  + libasprintf                        0.25.1  h3f43e3d_1            conda-forge       54kB\n",
            "  + graphite2                          1.3.14  hecca717_2            conda-forge      100kB\n",
            "  + zstd                                1.5.7  hb8e6e7a_2            conda-forge      568kB\n",
            "  + jsoncpp                             1.9.6  hf42df4d_1            conda-forge      169kB\n",
            "  + libstdcxx-ng                       15.2.0  h4852527_7            conda-forge       29kB\n",
            "  + libunistring                       0.9.10  h7f98852_0            conda-forge        1MB\n",
            "  + libev                                4.33  hd590300_2            conda-forge     Cached\n",
            "  + libxcrypt                          4.4.36  hd590300_1            conda-forge     Cached\n",
            "  + giflib                              5.2.2  hd590300_0            conda-forge       77kB\n",
            "  + lp_solve                         5.5.2.11  hd590300_0            conda-forge      410kB\n",
            "  + libssh2                            1.11.1  hcf80075_0            conda-forge      305kB\n",
            "  + libopenssl-static                   3.5.4  hb03c661_0            conda-forge        3MB\n",
            "  + xorg-libsm                          1.2.6  he73a12e_0            conda-forge       28kB\n",
            "  + brotli-bin                          1.1.0  hb03c661_4            conda-forge       20kB\n",
            "  + xorg-libx11                        1.8.12  h4f16b4b_0            conda-forge      836kB\n",
            "  + libopenblas                        0.3.30  pthreads_h94d23a6_2   conda-forge        6MB\n",
            "  + libgfortran-ng                     15.2.0  h69a702a_7            conda-forge       29kB\n",
            "  + libsuitesparseconfig               7.10.1  h92d6892_7100102      conda-forge       43kB\n",
            "  + xz                                  5.8.1  hbcc6ac9_2            conda-forge       24kB\n",
            "  + sqlite                             3.50.4  hbc0de68_0            conda-forge      166kB\n",
            "  + libglib                            2.86.0  h1fed272_0            conda-forge        4MB\n",
            "  + libfreetype6                       2.14.1  h73754d4_0            conda-forge      387kB\n",
            "  + libtiff                             4.7.1  h8261f1e_0            conda-forge      437kB\n",
            "  + gmp                                 6.3.0  hac33072_2            conda-forge      460kB\n",
            "  + qhull                              2020.2  h434a139_5            conda-forge      553kB\n",
            "  + krb5                               1.21.3  h659f571_0            conda-forge     Cached\n",
            "  + mysql-connector-c                  6.1.11  h659d440_1008         conda-forge        1MB\n",
            "  + icu                                  75.1  he02047a_0            conda-forge       12MB\n",
            "  + pcre                                 8.45  h9c3ff4c_0            conda-forge      259kB\n",
            "  + libidn2                             2.3.8  hfac485b_1            conda-forge      139kB\n",
            "  + libnghttp2                         1.67.0  had1ee68_0            conda-forge      667kB\n",
            "  + perl                               5.32.1  7_hd590300_perl5      conda-forge       13MB\n",
            "  + python                            3.11.14  hfe2f287_1_cpython    conda-forge       31MB\n",
            "  + brotli                              1.1.0  hb03c661_4            conda-forge       20kB\n",
            "  + xorg-libxfixes                      6.0.2  hb03c661_0            conda-forge       20kB\n",
            "  + xorg-libxt                          1.3.1  hb9d3cd8_0            conda-forge      380kB\n",
            "  + xorg-libxrender                    0.9.12  hb9d3cd8_0            conda-forge       33kB\n",
            "  + xorg-libxext                        1.3.6  hb9d3cd8_0            conda-forge       50kB\n",
            "  + libblas                             3.9.0  37_h4a7cf45_openblas  conda-forge       17kB\n",
            "  + openmpi                             4.1.6  hc5af2df_101          conda-forge        4MB\n",
            "  + librbio                             4.3.4  h32481e8_7100102      conda-forge       48kB\n",
            "  + libldl                              3.3.2  h32481e8_7100102      conda-forge       24kB\n",
            "  + libcxsparse                         4.4.1  h32481e8_7100102      conda-forge      121kB\n",
            "  + libcolamd                           3.3.4  h32481e8_7100102      conda-forge       34kB\n",
            "  + libccolamd                          3.3.4  h32481e8_7100102      conda-forge       43kB\n",
            "  + libcamd                             3.3.3  h32481e8_7100102      conda-forge       47kB\n",
            "  + libbtf                              2.3.2  h32481e8_7100102      conda-forge       28kB\n",
            "  + libamd                              3.3.3  haaf9dc3_7100102      conda-forge       50kB\n",
            "  + libfreetype                        2.14.1  ha770c72_0            conda-forge        8kB\n",
            "  + openjpeg                            2.5.4  h55fea9a_0            conda-forge      355kB\n",
            "  + lcms2                                2.17  h717163a_0            conda-forge      248kB\n",
            "  + mpfr                                4.2.1  h90cbb55_3            conda-forge      635kB\n",
            "  + libcups                             2.3.3  hb8b1518_5            conda-forge        5MB\n",
            "  + libboost                           1.85.0  h0ccab89_4            conda-forge        3MB\n",
            "  + wget                               1.21.4  hda4d442_0            conda-forge      770kB\n",
            "  + libcurl                            8.16.0  h4e3cde8_0            conda-forge      460kB\n",
            "  + perl-try-tiny                        0.31  pl5321ha770c72_0      conda-forge       18kB\n",
            "  + perl-compress-raw-zlib              2.213  pl5321h4dac143_0      conda-forge       81kB\n",
            "  + perl-compress-raw-bzip2             2.213  pl5321hda65f42_0      conda-forge       55kB\n",
            "  + perl-role-tiny                   2.002004  pl5321ha770c72_0      conda-forge       23kB\n",
            "  + perl-storable                        3.15  pl5321hb9d3cd8_2      conda-forge       71kB\n",
            "  + perl-inc-latest                     0.500  pl5321ha770c72_0      conda-forge       16kB\n",
            "  + perl-scalar-list-utils               1.70  pl5321hb03c661_0      conda-forge       52kB\n",
            "  + perl-dbi                            1.647  pl5321hb03c661_0      conda-forge      601kB\n",
            "  + xorg-libxrandr                      1.5.4  hb9d3cd8_0            conda-forge       30kB\n",
            "  + xorg-libxi                          1.8.2  hb9d3cd8_0            conda-forge       47kB\n",
            "  + liblapack                           3.9.0  37_h47877c9_openblas  conda-forge       17kB\n",
            "  + libcblas                            3.9.0  37_h0358290_openblas  conda-forge       17kB\n",
            "  + freetype                           2.14.1  ha770c72_0            conda-forge      173kB\n",
            "  + gawk                                5.3.1  hcd3d067_0            conda-forge        1MB\n",
            "  + libspex                             3.2.3  had10066_7100102      conda-forge       81kB\n",
            "  + libboost-devel                     1.85.0  h00ab1b0_4            conda-forge       41kB\n",
            "  + curl                               8.16.0  h4e3cde8_0            conda-forge      183kB\n",
            "  + perl-test-fatal                     0.016  pl5321ha770c72_0      conda-forge       20kB\n",
            "  + perl-module-build                  0.4234  pl5321ha770c72_1      conda-forge      137kB\n",
            "  + xorg-libxtst                        1.2.5  hb9d3cd8_3            conda-forge       33kB\n",
            "  + libcholmod                          5.3.1  h59ddab4_7100102      conda-forge        1MB\n",
            "  + gsl                                   2.8  hbf7d49c_1            conda-forge        2MB\n",
            "  + fontconfig                         2.15.0  h7e30c49_1            conda-forge      266kB\n",
            "  + mafft                               7.526  h4bc722e_0            conda-forge        3MB\n",
            "  + boost-cpp                          1.85.0  h3c6214e_4            conda-forge       18kB\n",
            "  + perl-sub-quote                   2.006006  pl5321ha770c72_0      conda-forge       27kB\n",
            "  + perl-class-method-modifiers          2.13  pl5321ha770c72_0      conda-forge       22kB\n",
            "  + libumfpack                          6.3.5  heb53515_7100102      conda-forge      434kB\n",
            "  + libspqr                             4.3.4  h852d39f_7100102      conda-forge      218kB\n",
            "  + libklu                              2.3.5  hf24d653_7100102      conda-forge      146kB\n",
            "  + cairo                              1.18.4  h3394656_0            conda-forge      978kB\n",
            "  + perl-moo                         2.005004  pl5321ha770c72_0      conda-forge       48kB\n",
            "  + libparu                             1.0.0  h17147ab_7100102      conda-forge       93kB\n",
            "  + harfbuzz                           12.1.0  h15599e2_0            conda-forge        2MB\n",
            "  + suitesparse                        7.10.1  ha0f6916_7100102      conda-forge       12kB\n",
            "  + openjdk                            24.0.2  h5755bd7_0            conda-forge      116MB\n",
            "  + raxml                              8.2.13  h7b50bb2_3            bioconda           3MB\n",
            "  + fasttree                            2.2.0  h7b50bb2_0            bioconda         205kB\n",
            "  + prodigal                            2.6.3  h577a1d6_11           bioconda         602kB\n",
            "  + miniprot                             0.18  h577a1d6_0            bioconda          71kB\n",
            "  + ncbi-vdb                            3.2.1  h9948957_0            bioconda          11MB\n",
            "  + prank                              170427  h9948957_1            bioconda         410kB\n",
            "  + muscle                           3.8.1551  h9948957_9            bioconda         274kB\n",
            "  + clustalw                              2.1  h9948957_12           bioconda         385kB\n",
            "  + cdbtools                             0.99  h077b44d_12           bioconda          80kB\n",
            "  + hmmer                                 3.4  h503566f_3            bioconda          12MB\n",
            "  + diamond                            2.1.13  h13889ed_0            bioconda          21MB\n",
            "  + bamtools                            2.5.3  he132191_0            bioconda         784kB\n",
            "  + ucsc-twobitinfo                       482  hdc0a859_0            bioconda         378kB\n",
            "  + ucsc-fatotwobit                       482  hdc0a859_0            bioconda         383kB\n",
            "  + perl-list-moreutils-xs              0.430  pl5321h7b50bb2_5      bioconda          52kB\n",
            "  + entrez-direct                        24.0  he881be0_0            bioconda          17MB\n",
            "  + htslib                             1.22.1  h566b1c6_0            bioconda           3MB\n",
            "  + metaeuk                         7.bba0d80  pl5321hd6d6fdc_2      bioconda           5MB\n",
            "  + pplacer                       1.1.alpha20  hd563303_0            bioconda          11MB\n",
            "  + samtools                           1.22.1  h96c455f_0            bioconda         499kB\n",
            "  + bbmap                               39.37  he5f24ec_0            bioconda          14MB\n",
            "  + perl-common-sense                    3.75  pl5321hd8ed1ab_0      conda-forge       20kB\n",
            "  + perl-exporter-tiny               1.002002  pl5321hd8ed1ab_0      conda-forge       29kB\n",
            "  + perl-extutils-makemaker              7.70  pl5321hd8ed1ab_0      conda-forge      157kB\n",
            "  + perl-parent                         0.243  pl5321hd8ed1ab_0      conda-forge       14kB\n",
            "  + perl-exporter                        5.74  pl5321hd8ed1ab_0      conda-forge       19kB\n",
            "  + perl-constant                        1.33  pl5321hd8ed1ab_0      conda-forge       16kB\n",
            "  + perl-file-which                      1.24  pl5321hd8ed1ab_0      conda-forge       17kB\n",
            "  + perl-app-cpanminus                 1.7048  pl5321hd8ed1ab_0      conda-forge      230kB\n",
            "  + wheel                              0.45.1  pyhd8ed1ab_1          conda-forge     Cached\n",
            "  + setuptools                         80.9.0  pyhff2d567_0          conda-forge      749kB\n",
            "  + perl-file-path                       2.18  pl5321hd8ed1ab_0      conda-forge       22kB\n",
            "  + perl-carp                            1.50  pl5321hd8ed1ab_0      conda-forge       22kB\n",
            "  + pip                                  25.2  pyh8b19718_0          conda-forge        1MB\n",
            "  + perl-file-temp                     0.2304  pl5321hd8ed1ab_0      conda-forge       32kB\n",
            "  + pycparser                            2.22  pyh29332c3_1          conda-forge     Cached\n",
            "  + sniffio                             1.3.1  pyhd8ed1ab_1          conda-forge       15kB\n",
            "  + six                                1.17.0  pyhe01879c_1          conda-forge       18kB\n",
            "  + pysocks                             1.7.1  pyha55dd90_7          conda-forge     Cached\n",
            "  + hyperframe                          6.1.0  pyhd8ed1ab_0          conda-forge       17kB\n",
            "  + hpack                               4.1.0  pyhd8ed1ab_0          conda-forge       31kB\n",
            "  + munkres                             1.1.4  pyhd8ed1ab_1          conda-forge       16kB\n",
            "  + pyparsing                           3.2.5  pyhcf101f3_0          conda-forge      104kB\n",
            "  + packaging                            25.0  pyh29332c3_1          conda-forge       62kB\n",
            "  + cycler                             0.12.1  pyhd8ed1ab_1          conda-forge       13kB\n",
            "  + python-tzdata                      2025.2  pyhd8ed1ab_0          conda-forge      144kB\n",
            "  + pytz                               2025.2  pyhd8ed1ab_0          conda-forge      189kB\n",
            "  + charset-normalizer                  3.4.4  pyhd8ed1ab_0          conda-forge       51kB\n",
            "  + idna                                 3.11  pyhd8ed1ab_0          conda-forge       51kB\n",
            "  + certifi                         2025.10.5  pyhd8ed1ab_0          conda-forge      160kB\n",
            "  + dnspython                           2.8.0  pyhcf101f3_0          conda-forge      196kB\n",
            "  + python-dateutil               2.9.0.post0  pyhe01879c_2          conda-forge      233kB\n",
            "  + h2                                  4.3.0  pyhcf101f3_0          conda-forge       96kB\n",
            "  + perl-io-zlib                         1.15  pl5321hdfd78af_1      bioconda          13kB\n",
            "  + perl-yaml                            1.30  pl5321hdfd78af_0      bioconda          44kB\n",
            "  + perl-types-serialiser                1.01  pl5321hdfd78af_0      bioconda          13kB\n",
            "  + perl-list-moreutils                 0.430  pl5321hdfd78af_0      bioconda          32kB\n",
            "  + dendropy                            5.0.8  pyhdfd78af_1          bioconda         335kB\n",
            "  + perl-parallel-forkmanager            2.04  pl5321hdfd78af_0      bioconda          24kB\n",
            "  + perl-encode                          3.21  pl5321hb9d3cd8_1      conda-forge        2MB\n",
            "  + perl-pathtools                       3.75  pl5321hb9d3cd8_2      conda-forge       51kB\n",
            "  + brotli-python                       1.1.0  py311h1ddb823_4       conda-forge      354kB\n",
            "  + unicodedata2                       16.0.0  py311h49ec1c0_1       conda-forge      405kB\n",
            "  + pillow                             11.3.0  py311h98278a2_3       conda-forge        1MB\n",
            "  + kiwisolver                          1.4.9  py311h724c32c_1       conda-forge       78kB\n",
            "  + numpy                               2.3.3  py311h2e04523_0       conda-forge        9MB\n",
            "  + cffi                                2.0.0  py311h5b438cf_0       conda-forge      304kB\n",
            "  + pymongo                            4.14.1  py311h1ddb823_0       conda-forge        2MB\n",
            "  + fonttools                          4.60.1  py311h3778330_0       conda-forge        3MB\n",
            "  + contourpy                           1.3.3  py311hdf67eae_2       conda-forge      297kB\n",
            "  + pandas                              2.3.3  py311hed34c8f_1       conda-forge       15MB\n",
            "  + biopython                            1.85  py311h49ec1c0_2       conda-forge        3MB\n",
            "  + zstandard                          0.25.0  py311haee01d2_0       conda-forge      467kB\n",
            "  + matplotlib-base                    3.10.7  py311h0f3be63_0       conda-forge        9MB\n",
            "  + perl-json-xs                         4.04  pl5321h9948957_0      bioconda          71kB\n",
            "  + perl-io-compress                    2.213  pl5321h503566f_0      bioconda          87kB\n",
            "  + pasta                               1.9.3  py311hefa8cab_0       bioconda           1MB\n",
            "  + augustus                            3.5.0  pl5321h9716f88_9      bioconda          27MB\n",
            "  + sepp                                4.5.6  py311haab0aaa_1       bioconda           2MB\n",
            "  + urllib3                             2.5.0  pyhd8ed1ab_0          conda-forge      102kB\n",
            "  + requests                           2.32.5  pyhd8ed1ab_0          conda-forge       59kB\n",
            "  + perl-json                            4.10  pl5321hdfd78af_1      bioconda          58kB\n",
            "  + perl-archive-tar                     3.04  pl5321hdfd78af_0      bioconda          35kB\n",
            "  + blast                              2.17.0  h66d330f_0            bioconda          85MB\n",
            "  + busco                               6.0.0  pyhdfd78af_1          bioconda         349kB\n",
            "\n",
            "  Summary:\n",
            "\n",
            "  Install: 237 packages\n",
            "\n",
            "  Total download: 535MB\n",
            "\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "\n",
            "\n",
            "\n",
            "Looking for: ['python=3.11', 'busco=6.0.0']\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages: ...working... done\n",
            "Preparing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Verifying transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b-  \n",
            "For Linux 64, Open MPI is built with CUDA awareness but this support is disabled by default.\n",
            "To enable it, please set the environment variable OMPI_MCA_opal_cuda_support=true before\n",
            "launching your MPI processes. Equivalently, you can set the MCA parameter in the command line:\n",
            "mpiexec --mca opal_cuda_support 1 ...\n",
            " \n",
            "In addition, the UCX support is also built but disabled by default.\n",
            "To enable it, first install UCX (conda install -c conda-forge ucx). Then, set the environment\n",
            "variables OMPI_MCA_pml=\"ucx\" OMPI_MCA_osc=\"ucx\" before launching your MPI processes.\n",
            "Equivalently, you can set the MCA parameters in the command line:\n",
            "mpiexec --mca pml ucx --mca osc ucx ...\n",
            "Note that you might also need to set UCX_MEMTYPE_CACHE=n for CUDA awareness via UCX.\n",
            "Please consult UCX's documentation for detail.\n",
            " \n",
            "\n",
            "\b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "\n",
            "To activate this environment, use\n",
            "\n",
            "     $ mamba activate busco\n",
            "\n",
            "To deactivate an active environment, use\n",
            "\n",
            "     $ mamba deactivate\n",
            "\n",
            "\n",
            "======================================================================\n",
            "STEP 3: Verifying installation...\n",
            "======================================================================\n",
            "üéâ SUCCESS! BUSCO 6.0.0 is installed correctly.\n",
            "\n",
            "üí° To run BUSCO, you must prefix your command like this:\n",
            "   !mamba run -n busco busco -i your_proteins.faa -m proteins ...\n"
          ]
        }
      ],
      "source": [
        "# @title Install BUSCO\n",
        "# @markdown Run this cell AFTER the kernel has restarted from the previous cell.\n",
        "# @markdown This will install BUSCO and all its dependencies (~3-5 minutes).\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "# Step 1: Clean up any previous failed environments to ensure a fresh start\n",
        "print(\"=\"*70)\n",
        "print(\"STEP 1: Cleaning up previous installation attempts...\")\n",
        "print(\"=\"*70)\n",
        "subprocess.run(\"mamba env remove -n busco -y\", shell=True, capture_output=True)\n",
        "print(\"‚úÖ Previous environments removed.\\n\")\n",
        "\n",
        "# Step 2: Install BUSCO and all dependencies with a single command\n",
        "print(\"=\"*70)\n",
        "print(\"STEP 2: Installing BUSCO v6...\")\n",
        "print(\"=\"*70)\n",
        "print(\"‚è≥ This will take 3-5 minutes...\\n\")\n",
        "\n",
        "# This one command creates a new environment and installs Python and BUSCO.\n",
        "# Mamba handles all dependencies (HMMER, pandas, biopython, etc.) correctly.\n",
        "install_cmd = 'mamba create -n busco -y -c conda-forge -c bioconda \"python=3.11\" \"busco=6.0.0\"'\n",
        "\n",
        "print(f\"üî© Running command: {install_cmd}\\n\")\n",
        "\n",
        "# Stream the output so you can monitor the progress\n",
        "process = subprocess.Popen(\n",
        "    install_cmd,\n",
        "    shell=True,\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.STDOUT,\n",
        "    text=True,\n",
        "    bufsize=1\n",
        ")\n",
        "for line in iter(process.stdout.readline, ''):\n",
        "    print(line, end='')\n",
        "process.wait()\n",
        "\n",
        "# Step 3: Final Verification\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STEP 3: Verifying installation...\")\n",
        "print(\"=\"*70)\n",
        "if process.returncode == 0:\n",
        "    verify_cmd = \"mamba run -n busco busco --version\"\n",
        "    busco_version = subprocess.run(verify_cmd, shell=True, capture_output=True, text=True)\n",
        "\n",
        "    if busco_version.returncode == 0:\n",
        "        print(f\"üéâ SUCCESS! {busco_version.stdout.strip()} is installed correctly.\")\n",
        "        print(\"\\nüí° To run BUSCO, you must prefix your command like this:\")\n",
        "        print(\"   !mamba run -n busco busco -i your_proteins.faa -m proteins ...\")\n",
        "    else:\n",
        "        print(\"‚ùå ERROR: Verification failed. The `busco` command is not working.\")\n",
        "        print(busco_version.stderr)\n",
        "else:\n",
        "    print(f\"‚ùå ERROR: Mamba installation failed with exit code {process.returncode}.\")\n",
        "    print(\"   Please review the log above.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJ1Z9TVnOU-u",
        "outputId": "de5910f5-24c3-40e0-f1ed-a8c8162e8976"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• Fetching all available BUSCO lineage datasets...\n",
            "‚úÖ Found 524 total lineages.\n",
            "\n",
            "======================================================================\n",
            "COPY a lineage name from the list below (e.g., 'metazoa_odb10')\n",
            "======================================================================\n",
            "acari_odb12\n",
            "acetobacter_odb12\n",
            "acetobacteraceae_odb12\n",
            "acholeplasmataceae_odb12\n",
            "achromobacter_odb12\n",
            "acidobacteriaceae_odb12\n",
            "acidobacteriota_odb12\n",
            "acidovorax_odb12\n",
            "acinetobacter_odb12\n",
            "aconoidasida_odb12\n",
            "actinomadura_odb12\n",
            "actinomyces_odb12\n",
            "actinomycetaceae_odb12\n",
            "actinomycetes_odb12\n",
            "actinomycetota_odb12\n",
            "actinoplanes_odb12\n",
            "actinopterygii_odb12\n",
            "aculeata_odb12\n",
            "aerococcaceae_odb12\n",
            "aeromicrobium_odb12\n",
            "aeromonadaceae_odb12\n",
            "aeromonas_odb12\n",
            "afipia_odb12\n",
            "agaricales_odb12\n",
            "agaricomycetes_odb12\n",
            "agrobacterium_group_odb12\n",
            "agrobacterium_odb12\n",
            "agromyces_odb12\n",
            "ajellomycetaceae_odb12\n",
            "alcaligenaceae_odb12\n",
            "alcanivorax_odb12\n",
            "algoriphagus_odb12\n",
            "alicyclobacillaceae_odb12\n",
            "alicyclobacillus_odb12\n",
            "alistipes_odb12\n",
            "alphabaculovirus_odb10\n",
            "alphaherpesvirinae_odb10\n",
            "alphaproteobacteria_odb12\n",
            "alteromonadales_odb12\n",
            "alteromonas_odb12\n",
            "alveolata_odb12\n",
            "amoebozoa_odb12\n",
            "amycolatopsis_odb12\n",
            "anaerococcus_odb12\n",
            "anaplasmataceae_odb12\n",
            "anopheles_odb12\n",
            "anthozoa_odb12\n",
            "apicomplexa_odb12\n",
            "apoidea_odb12\n",
            "aquificae_odb12\n",
            "aquimarina_odb12\n",
            "arachnida_odb12\n",
            "araneae_odb12\n",
            "archaea_odb12\n",
            "arcobacter_odb12\n",
            "arthrobacter_odb12\n",
            "arthropoda_odb12\n",
            "artiodactyla_odb12\n",
            "ascomycota_odb12\n",
            "aspergillus_odb12\n",
            "asticcacaulis_odb12\n",
            "atopobiaceae_odb12\n",
            "aurantimonadaceae_odb12\n",
            "aureimonas_odb12\n",
            "aves_odb12\n",
            "aviadenovirus_odb10\n",
            "azospirillum_odb12\n",
            "bacillaceae_odb12\n",
            "bacillales_odb12\n",
            "bacillariophyta_odb12\n",
            "bacilli_odb12\n",
            "bacillota_odb12\n",
            "bacillus_odb12\n",
            "bacteria_odb12\n",
            "bacteroidales_odb12\n",
            "bacteroides_odb12\n",
            "bacteroidia_odb12\n",
            "baculoviridae_odb10\n",
            "bartonella_odb12\n",
            "basidiomycota_odb12\n",
            "bclasvirinae_odb10\n",
            "betabaculovirus_odb10\n",
            "betaherpesvirinae_odb10\n",
            "betaproteobacteria_odb12\n",
            "bifidobacteriaceae_odb12\n",
            "bifidobacterium_odb12\n",
            "blautia_odb12\n",
            "boletales_odb12\n",
            "bordetella_odb12\n",
            "borreliaceae_odb12\n",
            "bosea_odb12\n",
            "brachybacterium_odb12\n",
            "brachycera_odb12\n",
            "brachyspira_odb12\n",
            "bradyrhizobium_odb12\n",
            "brassicales_odb12\n",
            "brevibacillus_odb12\n",
            "brevibacterium_odb12\n",
            "brevundimonas_odb12\n",
            "buchnera_odb12\n",
            "burkholderia_odb12\n",
            "burkholderiaceae_odb12\n",
            "burkholderiales_odb12\n",
            "butyrivibrio_odb12\n",
            "campylobacterota_odb12\n",
            "capnocytophaga_odb12\n",
            "carnivora_odb12\n",
            "carnobacteriaceae_odb12\n",
            "carnobacterium_odb12\n",
            "caulobacter_odb12\n",
            "caulobacteraceae_odb12\n",
            "cellulomonadaceae_odb12\n",
            "cellvibrionaceae_odb12\n",
            "cellvibrionales_odb12\n",
            "chaetothyriales_odb12\n",
            "cheoctovirus_odb10\n",
            "chitinophagaceae_odb12\n",
            "chlamydia_odb12\n",
            "chlamydiota_odb12\n",
            "chlorobiota_group_odb12\n",
            "chlorobiota_odb12\n",
            "chloroflexota_odb12\n",
            "chlorophyceae_odb12\n",
            "chlorophyta_odb12\n",
            "chordopoxvirinae_odb10\n",
            "chromadorea_odb12\n",
            "chromatiaceae_odb12\n",
            "chromatiales_odb12\n",
            "chromobacteriaceae_odb12\n",
            "chroococcales_odb12\n",
            "chryseobacterium_odb12\n",
            "chytridiomycota_odb12\n",
            "ciliophora_odb12\n",
            "citrobacter_odb12\n",
            "clavicipitaceae_odb12\n",
            "clostridia_odb12\n",
            "clostridiaceae_odb12\n",
            "cnidaria_odb12\n",
            "coccidia_odb12\n",
            "coleoptera_odb12\n",
            "collinsella_odb12\n",
            "colwellia_odb12\n",
            "comamonadaceae_odb12\n",
            "comamonas_odb12\n",
            "cordycipitaceae_odb12\n",
            "coriobacteriia_odb12\n",
            "corynebacterium_odb12\n",
            "crustacea_odb12\n",
            "cryptosporidium_odb12\n",
            "culicidae_odb12\n",
            "cupriavidus_odb12\n",
            "curtobacterium_odb12\n",
            "cyanobacteriota_odb12\n",
            "cyclobacteriaceae_odb12\n",
            "cyprinodontiformes_odb12\n",
            "cytophagaceae_odb12\n",
            "cytophagia_odb12\n",
            "debaryomycetaceae_odb12\n",
            "deinococcus_odb12\n",
            "deltaproteobacteria_odb12\n",
            "desulfobacteraceae_odb12\n",
            "desulfobacterales_odb12\n",
            "desulfosporosinus_odb12\n",
            "desulfovibrionales_odb12\n",
            "desulfurococcaceae_odb12\n",
            "desulfurococcales_odb12\n",
            "desulfuromonadales_odb12\n",
            "devosia_odb12\n",
            "diptera_odb12\n",
            "dothideomycetes_odb12\n",
            "drosophila_odb12\n",
            "drosophilidae_odb12\n",
            "dysgonomonas_odb12\n",
            "ectothiorhodospiraceae_odb12\n",
            "eggerthellaceae_odb12\n",
            "embryophyta_odb12\n",
            "endopterygota_odb12\n",
            "enquatrovirus_odb10\n",
            "enterobacter_odb12\n",
            "enterobacterales_odb12\n",
            "enterobacteriaceae_odb12\n",
            "enterococcaceae_odb12\n",
            "enterococcus_odb12\n",
            "entomoplasmatales_odb12\n",
            "epsilon_subdivisions_odb12\n",
            "erwinia_odb12\n",
            "erwiniaceae_odb12\n",
            "erysipelotrichaceae_odb12\n",
            "erythrobacter_odb12\n",
            "erythrobacteraceae_odb12\n",
            "euarchontoglires_odb12\n",
            "eubacteriaceae_odb12\n",
            "eubacteriales_odb12\n",
            "eudicotyledons_odb12\n",
            "euglenozoa_odb12\n",
            "eukaryota_odb12\n",
            "eurotiales_odb12\n",
            "eurotiomycetes_odb12\n",
            "euryarchaeota_odb12\n",
            "eutheria_odb12\n",
            "exiguobacterium_odb12\n",
            "fabales_odb12\n",
            "flavobacteriia_odb12\n",
            "flavobacterium_odb12\n",
            "formicidae_odb12\n",
            "francisellaceae_odb12\n",
            "frankia_odb12\n",
            "fromanvirus_odb10\n",
            "fungi_odb12\n",
            "fusobacteriaceae_odb12\n",
            "fusobacteriota_odb12\n",
            "fusobacterium_odb12\n",
            "galloanserae_odb12\n",
            "gammaherpesvirinae_odb10\n",
            "gammaproteobacteria_odb12\n",
            "geobacter_odb12\n",
            "geobacteraceae_odb12\n",
            "glires_odb12\n",
            "glomerellales_odb12\n",
            "gordonia_odb12\n",
            "guernseyvirinae_odb10\n",
            "haloarcula_odb12\n",
            "haloarculaceae_odb12\n",
            "halobacteria_odb12\n",
            "halobacteriaceae_odb12\n",
            "halobacteriales_odb12\n",
            "haloferacaceae_odb12\n",
            "haloferacales_odb12\n",
            "haloferax_odb12\n",
            "halomonadaceae_odb12\n",
            "halomonas_odb12\n",
            "halorubrum_odb12\n",
            "haloterrigena_odb12\n",
            "helotiales_odb12\n",
            "hemiptera_odb12\n",
            "herbaspirillum_odb12\n",
            "herpesviridae_odb10\n",
            "hexapoda_odb12\n",
            "hymenobacter_odb12\n",
            "hymenobacteraceae_odb12\n",
            "hymenoptera_odb12\n",
            "hyphomicrobiaceae_odb12\n",
            "hyphomicrobiales_odb12\n",
            "hyphomicrobium_odb12\n",
            "hyphomonadaceae_odb12\n",
            "hyphomonas_odb12\n",
            "hypocreaceae_odb12\n",
            "hypocreales_odb12\n",
            "idiomarina_odb12\n",
            "insecta_odb12\n",
            "intrasporangiaceae_odb12\n",
            "iridoviridae_odb10\n",
            "jannaschia_odb12\n",
            "janthinobacterium_odb12\n",
            "kitasatospora_odb12\n",
            "kitasatosporales_odb12\n",
            "kocuria_odb12\n",
            "labrenzia_odb12\n",
            "lachnoclostridium_odb12\n",
            "lachnospiraceae_odb12\n",
            "lactobacillaceae_odb12\n",
            "lactobacillales_odb12\n",
            "lactobacillus_odb12\n",
            "lamiales_odb12\n",
            "laurasiatheria_odb12\n",
            "legionellaceae_odb12\n",
            "legionellales_odb12\n",
            "leifsonia_odb12\n",
            "leishmaniinae_odb12\n",
            "leotiomycetes_odb12\n",
            "lepidoptera_odb12\n",
            "leptolyngbya_odb12\n",
            "leptospiraceae_odb12\n",
            "leptotrichia_odb12\n",
            "leucobacter_odb12\n",
            "liliopsida_odb12\n",
            "listeria_odb12\n",
            "listeriaceae_odb12\n",
            "loktanella_odb12\n",
            "lophotrochozoa_odb12\n",
            "luteimonas_odb12\n",
            "lysinibacillus_odb12\n",
            "lysobacter_odb12\n",
            "malpighiales_odb12\n",
            "mammalia_odb12\n",
            "maribacter_odb12\n",
            "marinobacter_odb12\n",
            "marinobacterium_odb12\n",
            "marinomonas_odb12\n",
            "massilia_odb12\n",
            "megasphaera_odb12\n",
            "meiothermus_odb12\n",
            "mesorhizobium_odb12\n",
            "metazoa_odb12\n",
            "methanobacteria_odb12\n",
            "methanobacterium_odb12\n",
            "methanobrevibacter_odb12\n",
            "methanococcaceae_odb12\n",
            "methanococcales_odb12\n",
            "methanomicrobia_odb12\n",
            "methanomicrobiaceae_odb12\n",
            "methanomicrobiales_odb12\n",
            "methanosarcina_odb12\n",
            "methanosarcinaceae_odb12\n",
            "methylobacteriaceae_odb12\n",
            "methylobacterium_odb12\n",
            "methylococcaceae_odb12\n",
            "methylophilaceae_odb12\n",
            "microbacteriaceae_odb12\n",
            "microbacterium_odb12\n",
            "microbotryomycetes_odb12\n",
            "micrococcaceae_odb12\n",
            "micrococcales_odb12\n",
            "micromonosporaceae_odb12\n",
            "microsporidia_odb12\n",
            "mollusca_odb12\n",
            "moraxella_odb12\n",
            "moraxellaceae_odb12\n",
            "morganellaceae_odb12\n",
            "mucorales_odb12\n",
            "mucoromycota_odb12\n",
            "mycobacteriaceae_odb12\n",
            "mycobacteriales_odb12\n",
            "mycobacterium_odb12\n",
            "mycolicibacterium_odb12\n",
            "mycoplasma_odb12\n",
            "mycoplasmatales_odb12\n",
            "mycoplasmatota_odb12\n",
            "mycosphaerellaceae_odb12\n",
            "natrialbaceae_odb12\n",
            "natrinema_odb12\n",
            "nectriaceae_odb12\n",
            "neisseria_odb12\n",
            "neisseriales_odb12\n",
            "nematocera_odb12\n",
            "nematoda_odb12\n",
            "nitrobacteraceae_odb12\n",
            "nitrosomonadales_odb12\n",
            "nitrosomonas_odb12\n",
            "nitrosopumilales_odb12\n",
            "nitrosopumilus_odb12\n",
            "nitrososphaerota_odb12\n",
            "nocardia_odb12\n",
            "nocardiaceae_odb12\n",
            "nocardioides_odb12\n",
            "nocardiopsaceae_odb12\n",
            "nocardiopsis_odb12\n",
            "nonlabens_odb12\n",
            "nostoc_odb12\n",
            "nostocales_odb12\n",
            "novosphingobium_odb12\n",
            "oceanobacillus_odb12\n",
            "oceanospirillaceae_odb12\n",
            "oceanospirillales_odb12\n",
            "olsenella_odb12\n",
            "onygenales_odb12\n",
            "oomycota_odb12\n",
            "ophiocordycipitaceae_odb12\n",
            "oscillatoriales_odb12\n",
            "oxalobacteraceae_odb12\n",
            "paenibacillaceae_odb12\n",
            "paenibacillus_odb12\n",
            "pahexavirus_odb10\n",
            "pandoraea_odb12\n",
            "pantoea_odb12\n",
            "papilionoidea_odb12\n",
            "paraburkholderia_odb12\n",
            "paracoccaceae_odb12\n",
            "paracoccus_odb12\n",
            "passeriformes_odb12\n",
            "pasteurellales_odb12\n",
            "pectobacteriaceae_odb12\n",
            "pectobacterium_odb12\n",
            "pediococcus_odb12\n",
            "pedobacter_odb12\n",
            "peduovirus_odb10\n",
            "pelagibacter_odb12\n",
            "penicillium_odb12\n",
            "peptococcaceae_odb12\n",
            "peptoniphilus_odb12\n",
            "peptostreptococcaceae_odb12\n",
            "phaeobacter_odb12\n",
            "photobacterium_odb12\n",
            "phyllobacteriaceae_odb12\n",
            "phytophthora_odb12\n",
            "phytoplasma_odb12\n",
            "pichiaceae_odb12\n",
            "piroplasmida_odb12\n",
            "piscirickettsiaceae_odb12\n",
            "planctomycetaceae_odb12\n",
            "planctomycetota_odb12\n",
            "planococcaceae_odb12\n",
            "planococcus_odb12\n",
            "plasmodium_odb12\n",
            "pleosporaceae_odb12\n",
            "pleosporales_odb12\n",
            "poales_odb12\n",
            "polaribacter_odb12\n",
            "polyphaga_odb12\n",
            "polyporaceae_odb12\n",
            "polyporales_odb12\n",
            "pontibacter_odb12\n",
            "porphyrobacter_odb12\n",
            "porphyromonadaceae_odb12\n",
            "poxviridae_odb10\n",
            "prevotellaceae_odb12\n",
            "primates_odb12\n",
            "prochlorococcus_odb12\n",
            "propionibacteriaceae_odb12\n",
            "propionibacteriales_odb12\n",
            "pseudeurotiaceae_odb12\n",
            "pseudoalteromonas_odb12\n",
            "pseudomonadales_odb12\n",
            "pseudomonadota_odb12\n",
            "pseudomonas_odb12\n",
            "pseudonocardia_odb12\n",
            "pseudonocardiaceae_odb12\n",
            "pseudoxanthomonas_odb12\n",
            "psychrobacter_odb12\n",
            "psychromonas_odb12\n",
            "pucciniomycetes_odb12\n",
            "ralstonia_odb12\n",
            "rhizobiaceae_odb12\n",
            "rhizobium_odb12\n",
            "rhodanobacteraceae_odb12\n",
            "rhodobacter_odb12\n",
            "rhodobacterales_odb12\n",
            "rhodococcus_odb12\n",
            "rhodophyta_odb12\n",
            "rhodopseudomonas_odb12\n",
            "rhodospirillaceae_odb12\n",
            "rhodospirillales_odb12\n",
            "rickettsiaceae_odb12\n",
            "rickettsiales_odb12\n",
            "rikenellaceae_odb12\n",
            "rodentia_odb12\n",
            "rosaceae_odb12\n",
            "rosales_odb12\n",
            "roseovarius_odb12\n",
            "rudiviridae_odb10\n",
            "ruegeria_odb12\n",
            "ruminococcus_odb12\n",
            "saccharomycetaceae_odb12\n",
            "saccharomycetes_odb12\n",
            "salinicoccus_odb12\n",
            "saprolegniaceae_odb12\n",
            "sauropsida_odb12\n",
            "selenomonadaceae_odb12\n",
            "selenomonadales_odb12\n",
            "selenomonas_odb12\n",
            "shewanella_odb12\n",
            "simplexvirus_odb10\n",
            "sinorhizobium_odb12\n",
            "skunavirus_odb10\n",
            "solanales_odb12\n",
            "sordariales_odb12\n",
            "sordariomycetes_odb12\n",
            "sphingobacteriia_odb12\n",
            "sphingobacterium_odb12\n",
            "sphingobium_odb12\n",
            "sphingomonadales_odb12\n",
            "sphingomonas_odb12\n",
            "sphingopyxis_odb12\n",
            "spirochaetaceae_odb12\n",
            "spirochaetales_odb12\n",
            "spirochaetota_odb12\n",
            "spiroplasma_odb12\n",
            "sporosarcina_odb12\n",
            "spounavirinae_odb10\n",
            "squamata_odb12\n",
            "staphylococcaceae_odb12\n",
            "staphylococcus_odb12\n",
            "stenotrophomonas_odb12\n",
            "stramenopiles_odb12\n",
            "streptacidiphilus_odb12\n",
            "streptococcaceae_odb12\n",
            "streptomyces_odb12\n",
            "streptosporangiales_odb12\n",
            "sulfitobacter_odb12\n",
            "sulfolobales_odb12\n",
            "synechococcaceae_odb12\n",
            "synechococcales_odb12\n",
            "synergistota_odb12\n",
            "tenacibaculum_odb12\n",
            "tequatrovirus_odb10\n",
            "teseptimavirus_odb10\n",
            "tetrapoda_odb12\n",
            "tevenvirinae_odb10\n",
            "thauera_odb12\n",
            "thermaceae_odb12\n",
            "thermoanaerobacterales_odb12\n",
            "thermococcaceae_odb12\n",
            "thermococcus_odb12\n",
            "thermoplasmata_odb12\n",
            "thermoproteaceae_odb12\n",
            "thermoproteales_odb12\n",
            "thermoprotei_odb12\n",
            "thermotogota_odb12\n",
            "thermus_odb12\n",
            "thioalkalivibrio_odb12\n",
            "thiotrichales_odb12\n",
            "tissierellia_odb12\n",
            "trebouxiophyceae_odb12\n",
            "tremellomycetes_odb12\n",
            "treponema_odb12\n",
            "trypanosoma_odb12\n",
            "tunavirinae_odb10\n",
            "ustilaginomycetes_odb12\n",
            "varicellovirus_odb10\n",
            "variovorax_odb12\n",
            "veillonella_odb12\n",
            "veillonellaceae_odb12\n",
            "verrucomicrobiota_odb12\n",
            "vertebrata_odb12\n",
            "vibrio_odb12\n",
            "vibrionales_odb12\n",
            "virgibacillus_odb12\n",
            "viridiplantae_odb12\n",
            "weissella_odb12\n",
            "xanthomonadales_odb12\n",
            "xanthomonas_odb12\n",
            "xylariales_odb12\n",
            "yersinia_odb12\n",
            "yersiniaceae_odb12\n",
            "\n",
            "‚û°Ô∏è Now, paste your chosen lineage into the text field in the next cell and run it.\n"
          ]
        }
      ],
      "source": [
        "# @title Fetch and Display Lineages\n",
        "# @markdown Run this cell to see all available BUSCO datasets.\n",
        "# @markdown Copy the name of the lineage you want from the output below.\n",
        "\n",
        "import subprocess\n",
        "import re\n",
        "\n",
        "print(\"üì• Fetching all available BUSCO lineage datasets...\")\n",
        "\n",
        "# Command to get the list\n",
        "cmd = \"mamba run -n busco busco --list-datasets\"\n",
        "result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
        "\n",
        "if result.returncode != 0:\n",
        "    print(\"\\n‚ùå FATAL ERROR: Could not retrieve dataset list.\")\n",
        "    print(\"   Please ensure the BUSCO installation (Cell 2 in the previous step) ran successfully.\")\n",
        "else:\n",
        "    # Find and sort all lineage names\n",
        "    output = result.stdout\n",
        "    lineage_pattern = r'([a-zA-Z_]+_odb\\d+)'\n",
        "    all_lineages = sorted(list(set(re.findall(lineage_pattern, output))))\n",
        "\n",
        "    print(f\"‚úÖ Found {len(all_lineages)} total lineages.\\n\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"COPY a lineage name from the list below (e.g., 'metazoa_odb10')\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Print the full list for the user\n",
        "    for lineage in all_lineages:\n",
        "        print(lineage)\n",
        "\n",
        "    print(\"\\n‚û°Ô∏è Now, paste your chosen lineage into the text field in the next cell and run it.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDVZcAsmXdRC",
        "outputId": "6d75ccf4-091e-4436-bd8f-c66ccfb36cce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ You have selected: **solanales_odb12**\n",
            "\n",
            "üì• Downloading 'solanales_odb12' dataset...\n",
            "   (This may take 1-5 minutes)\n",
            "\n",
            "‚úÖ **SUCCESS!** Dataset 'solanales_odb12' is ready.\n",
            "üìÇ Dataset location: /content/busco_downloads/lineages/solanales_odb12\n",
            "\n",
            "‚û°Ô∏è You are now ready to run the BUSCO analysis.\n"
          ]
        }
      ],
      "source": [
        "# @title Select and Download Your Chosen Lineage\n",
        "# @markdown 1. Run the cell above and copy a lineage name.\n",
        "# @markdown 2. Paste it into the `lineage_to_download` field below.\n",
        "# @markdown 3. Run this cell.\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "# @markdown ---\n",
        "lineage_to_download = \"solanales_odb12\" # @param {type:\"string\"}\n",
        "# @markdown ---\n",
        "\n",
        "if not lineage_to_download.strip():\n",
        "    print(\"‚ùå ERROR: The `lineage_to_download` field is empty. Please paste a lineage name and run again.\")\n",
        "    sys.exit()\n",
        "\n",
        "final_lineage = lineage_to_download.strip()\n",
        "print(f\"‚úÖ You have selected: **{final_lineage}**\")\n",
        "\n",
        "# Set up download path and config file\n",
        "busco_downloads_path = \"/content/busco_downloads\"\n",
        "os.makedirs(busco_downloads_path, exist_ok=True)\n",
        "\n",
        "config_path = '/content/busco_config.ini'\n",
        "with open(config_path, 'w') as f:\n",
        "    f.write(f\"[busco]\\ndownload_path = {busco_downloads_path}\\n\")\n",
        "\n",
        "print(f\"\\nüì• Downloading '{final_lineage}' dataset...\")\n",
        "print(\"   (This may take 1-5 minutes)\\n\")\n",
        "\n",
        "# Run the download command\n",
        "cmd_download = f\"mamba run -n busco busco --download {final_lineage} --config {config_path}\"\n",
        "result = subprocess.run(cmd_download, shell=True, capture_output=True, text=True)\n",
        "\n",
        "# Verify the download - accept multiple success indicators\n",
        "success_indicators = [\n",
        "    \"successfully downloaded\",\n",
        "    \"is the last available version\",\n",
        "    \"Decompressing file\"\n",
        "]\n",
        "\n",
        "download_successful = result.returncode == 0 and any(indicator in result.stdout for indicator in success_indicators)\n",
        "\n",
        "if download_successful:\n",
        "    print(f\"‚úÖ **SUCCESS!** Dataset '{final_lineage}' is ready.\")\n",
        "\n",
        "    lineage_path = os.path.join(busco_downloads_path, \"lineages\", final_lineage)\n",
        "\n",
        "    if os.path.exists(lineage_path):\n",
        "        print(f\"üìÇ Dataset location: {lineage_path}\")\n",
        "\n",
        "        # Save the name for the final analysis step\n",
        "        with open('/content/selected_lineage.txt', 'w') as f:\n",
        "            f.write(final_lineage)\n",
        "\n",
        "        print(\"\\n‚û°Ô∏è You are now ready to run the BUSCO analysis.\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Download reported success, but the directory was not found at:\")\n",
        "        print(f\"   {lineage_path}\")\n",
        "        print(\"\\nüîç Check the output above for the actual download location.\")\n",
        "else:\n",
        "    print(f\"‚ùå **ERROR:** Failed to download '{final_lineage}'\")\n",
        "    print(\"\\n**BUSCO Error Message:**\")\n",
        "    print(result.stderr if result.stderr else result.stdout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "L6UoMMcIOaB5",
        "outputId": "ae0715c0-6ae9-4556-aeca-966d90b27067"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÑ Proteome File Upload\n",
            "\n",
            "Please select your proteome FASTA file...\n",
            "Accepted formats: .faa, .fasta, .fa, .pep, .faa.gz, .fasta.gz, .fa.gz\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3bc0030e-742e-496f-ad1f-12c70a571ae8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3bc0030e-742e-496f-ad1f-12c70a571ae8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving NbT2T.pep.fasta.gz to NbT2T.pep.fasta.gz\n",
            "\n",
            "üóúÔ∏è Decompressing NbT2T.pep.fasta.gz...\n",
            "‚úÖ Decompressed to: NbT2T.pep.fasta\n",
            "\n",
            "‚úÖ File uploaded: NbT2T.pep.fasta\n",
            "   Location: /content/NbT2T.pep.fasta\n",
            "\n",
            "üîç Validating proteome file...\n",
            "   File size: 20.39 MB\n",
            "   ‚úÖ Valid FASTA format detected\n",
            "   üìä Estimated protein sequences: ~101500\n",
            "\n",
            "‚úÖ Proteome file ready for BUSCO analysis!\n",
            "   Path saved for next step: /content/NbT2T.pep.fasta\n"
          ]
        }
      ],
      "source": [
        "# @title **Upload Proteome File** { display-mode: \"form\" }\n",
        "# @markdown Upload your proteome FASTA file or specify a path from Google Drive.\n",
        "# @markdown ---\n",
        "upload_method = \"Upload from computer\" # @param [\"Upload from computer\", \"Use Google Drive path\"]\n",
        "drive_path = \"\" # @param {type:\"string\"}\n",
        "# @markdown **Upload Method:**\n",
        "# @markdown - `Upload from computer` - Direct file upload (recommended for files < 100 MB)\n",
        "# @markdown - `Use Google Drive path` - Path to file in your Drive (e.g., `/content/drive/MyDrive/my_proteome.faa`)\n",
        "\n",
        "import os\n",
        "import gzip\n",
        "from google.colab import files\n",
        "\n",
        "proteome_path = None\n",
        "\n",
        "print(\"üìÑ Proteome File Upload\\n\")\n",
        "\n",
        "if upload_method == \"Upload from computer\":\n",
        "    print(\"Please select your proteome FASTA file...\")\n",
        "    print(\"Accepted formats: .faa, .fasta, .fa, .pep, .faa.gz, .fasta.gz, .fa.gz\\n\")\n",
        "\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if uploaded:\n",
        "        filename = list(uploaded.keys())[0]\n",
        "\n",
        "        # Handle .gz decompression\n",
        "        if filename.endswith('.gz'):\n",
        "            print(f\"\\nüóúÔ∏è Decompressing {filename}...\")\n",
        "            decompressed_filename = filename[:-3]\n",
        "\n",
        "            with gzip.open(filename, 'rt') as f_in:\n",
        "                with open(decompressed_filename, 'w') as f_out:\n",
        "                    f_out.write(f_in.read())\n",
        "\n",
        "            os.remove(filename)\n",
        "            filename = decompressed_filename\n",
        "            print(f\"‚úÖ Decompressed to: {filename}\")\n",
        "\n",
        "        proteome_path = f\"/content/{filename}\"\n",
        "        print(f\"\\n‚úÖ File uploaded: {filename}\")\n",
        "        print(f\"   Location: {proteome_path}\")\n",
        "    else:\n",
        "        print(\"‚ùå No file uploaded. Please run this cell again and select a file.\")\n",
        "\n",
        "elif upload_method == \"Use Google Drive path\":\n",
        "    if drive_path.strip():\n",
        "        # Handle .gz in Drive path\n",
        "        if drive_path.endswith('.gz'):\n",
        "            if os.path.exists(drive_path):\n",
        "                print(f\"üóúÔ∏è Decompressing {os.path.basename(drive_path)}...\")\n",
        "                decompressed_path = drive_path[:-3]\n",
        "\n",
        "                with gzip.open(drive_path, 'rt') as f_in:\n",
        "                    with open(decompressed_path, 'w') as f_out:\n",
        "                        f_out.write(f_in.read())\n",
        "\n",
        "                proteome_path = decompressed_path\n",
        "                print(f\"‚úÖ Decompressed and found file at: {decompressed_path}\")\n",
        "            else:\n",
        "                print(f\"‚ùå File not found: {drive_path}\")\n",
        "                print(\"Please check the path and make sure Google Drive is mounted.\")\n",
        "        else:\n",
        "            if os.path.exists(drive_path):\n",
        "                proteome_path = drive_path\n",
        "                print(f\"‚úÖ Found file at: {drive_path}\")\n",
        "            else:\n",
        "                print(f\"‚ùå File not found: {drive_path}\")\n",
        "                print(\"Please check the path and make sure Google Drive is mounted.\")\n",
        "    else:\n",
        "        print(\"‚ùå Please enter a valid Google Drive path in the 'drive_path' field above.\")\n",
        "\n",
        "# Validate the proteome file\n",
        "if proteome_path and os.path.exists(proteome_path):\n",
        "    print(\"\\nüîç Validating proteome file...\")\n",
        "\n",
        "    # Check file size\n",
        "    file_size_mb = os.path.getsize(proteome_path) / (1024 * 1024)\n",
        "    print(f\"   File size: {file_size_mb:.2f} MB\")\n",
        "\n",
        "    # Quick FASTA format check\n",
        "    with open(proteome_path, 'r') as f:\n",
        "        first_lines = [f.readline() for _ in range(5)]\n",
        "\n",
        "    if first_lines[0].startswith('>'):\n",
        "        print(\"   ‚úÖ Valid FASTA format detected\")\n",
        "\n",
        "        # Count sequences (rough estimate from first 1000 lines)\n",
        "        with open(proteome_path, 'r') as f:\n",
        "            sample = [f.readline() for _ in range(1000)]\n",
        "            seq_count_estimate = sum(1 for line in sample if line.startswith('>'))\n",
        "\n",
        "        if seq_count_estimate > 0:\n",
        "            print(f\"   üìä Estimated protein sequences: ~{seq_count_estimate * max(1, int(file_size_mb / 0.1))}\")\n",
        "\n",
        "        print(\"\\n‚úÖ Proteome file ready for BUSCO analysis!\")\n",
        "        print(f\"   Path saved for next step: {proteome_path}\")\n",
        "\n",
        "        # Store path for next cell\n",
        "        with open('/content/proteome_path.txt', 'w') as f:\n",
        "            f.write(proteome_path)\n",
        "    else:\n",
        "        print(\"   ‚ö†Ô∏è Warning: File doesn't appear to be in FASTA format\")\n",
        "        print(\"   FASTA files should start with '>' followed by sequence ID\")\n",
        "        print(\"   BUSCO may fail if the format is incorrect.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "F-uJtCfSOeuc",
        "outputId": "fab97aab-1c50-4264-88fb-e2e934f51b39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Starting BUSCO Analysis\n",
            "\n",
            "============================================================\n",
            "CPU CONFIGURATION\n",
            "============================================================\n",
            "üñ•Ô∏è  Detected CPU threads: 24\n",
            "‚úÖ High-RAM Runtime detected - GOOD performance (8 threads)\n",
            "‚öôÔ∏è  BUSCO will use all 24 threads (100% CPU utilization)\n",
            "============================================================\n",
            "\n",
            "üìù Output name: NbT2T.pep (auto-detected)\n",
            "\n",
            "üîç Detecting BUSCO version...\n",
            "‚úÖ BUSCO version: 6.0.0\n",
            "\n",
            "üßπ Cleaning FASTA headers...\n",
            "‚úÖ 0 headers cleaned\n",
            "\n",
            "üìÅ Results will be saved as: NbT2T.pep_BUSCOv6.0.0_solanales_odb12\n",
            "\n",
            "üìä Analysis Configuration:\n",
            "   Proteome: NbT2T.pep.fasta\n",
            "   Sequences: 57,023\n",
            "   Lineage: solanales_odb12\n",
            "   CPU threads: 24\n",
            "\n",
            "‚è≥ Estimated time: 114-456 minutes\n",
            "‚è∞ Started: 17:56:23\n",
            "\n",
            "============================================================\n",
            "üìà BUSCO Progress (live output - using 24 threads):\n",
            "============================================================\n",
            "2025-10-21 17:56:25 INFO:\t***** Start a BUSCO v6.0.0 analysis, current time: 10/21/2025 17:56:25 *****\n",
            "2025-10-21 17:56:25 INFO:\tConfiguring BUSCO with local environment\n",
            "‚öôÔ∏è 2025-10-21 17:56:25 INFO:\tRunning proteins mode\n",
            "2025-10-21 17:56:25 INFO:\t'Force' option selected; overwriting previous results directory\n",
            "2025-10-21 17:56:25 INFO:\tInput file is /content/NbT2T.pep.fasta\n",
            "‚öôÔ∏è 2025-10-21 17:56:25 INFO:\tRunning BUSCO using lineage dataset solanales_odb12 (eukaryota, 2025-07-01)\n",
            "2025-10-21 17:56:25 INFO:\t***** Run HMMER on gene sequences *****\n",
            "‚öôÔ∏è 2025-10-21 17:56:25 INFO:\tRunning 7934 job(s) on hmmsearch, starting at 10/21/2025 17:56:25\n",
            "2025-10-21 17:57:34 INFO:\t[hmmsearch]\t794 of 7934 task(s) completed\n",
            "2025-10-21 17:59:06 INFO:\t[hmmsearch]\t1587 of 7934 task(s) completed\n",
            "2025-10-21 18:00:38 INFO:\t[hmmsearch]\t2381 of 7934 task(s) completed\n",
            "2025-10-21 18:02:00 INFO:\t[hmmsearch]\t3174 of 7934 task(s) completed\n",
            "2025-10-21 18:03:15 INFO:\t[hmmsearch]\t3967 of 7934 task(s) completed\n",
            "2025-10-21 18:04:26 INFO:\t[hmmsearch]\t4761 of 7934 task(s) completed\n",
            "2025-10-21 18:05:27 INFO:\t[hmmsearch]\t5554 of 7934 task(s) completed\n",
            "2025-10-21 18:06:38 INFO:\t[hmmsearch]\t6348 of 7934 task(s) completed\n",
            "2025-10-21 18:07:35 INFO:\t[hmmsearch]\t7141 of 7934 task(s) completed\n",
            "2025-10-21 18:08:55 INFO:\t[hmmsearch]\t7934 of 7934 task(s) completed\n",
            "2025-10-21 18:10:23 INFO:\n",
            "\n",
            "    ---------------------------------------------------\n",
            "üìä     |Results from dataset solanales_odb12              |\n",
            "    ---------------------------------------------------\n",
            "    |C:98.2%[S:34.3%,D:63.9%],F:0.5%,M:1.4%,n:7934     |\n",
            "    |7789    Complete BUSCOs (C)                       |\n",
            "    |2720    Complete and single-copy BUSCOs (S)       |\n",
            "    |5069    Complete and duplicated BUSCOs (D)        |\n",
            "    |37    Fragmented BUSCOs (F)                       |\n",
            "    |108    Missing BUSCOs (M)                         |\n",
            "    |7934    Total BUSCO groups searched               |\n",
            "    ---------------------------------------------------\n",
            "2025-10-21 18:10:23 INFO:\tBUSCO analysis done. Total running time: 838 seconds\n",
            "üìä 2025-10-21 18:10:23 INFO:\tResults written in /content/busco_temp_NbT2T.pep\n",
            "2025-10-21 18:10:23 INFO:\tFor assistance with interpreting the results, please consult the userguide: https://busco.ezlab.org/busco_userguide.html\n",
            "\n",
            "2025-10-21 18:10:23 INFO:\tVisit this page https://gitlab.com/ezlab/busco#how-to-cite-busco to see how to cite BUSCO\n",
            "2025-10-21 18:10:23 INFO:\tThank you for using BUSCO! Anonymous usage data is gathered to improve the tool. You may opt out with --opt-out-run-stats.\n",
            "\n",
            "============================================================\n",
            "‚è±Ô∏è Completed in 14.0 minutes using 24 CPU threads\n",
            "============================================================\n",
            "\n",
            "‚úÖ BUSCO Analysis Complete!\n",
            "\n",
            "üìä BUSCO RESULTS SUMMARY:\n",
            "============================================================\n",
            "# BUSCO version is: 6.0.0 \n",
            "# The lineage dataset is: solanales_odb12 (Creation date: 2025-07-01, number of genomes: 9, number of BUSCOs: 7934)\n",
            "# Summarized benchmarking in BUSCO notation for file /content/NbT2T.pep.fasta\n",
            "# BUSCO was run in mode: proteins\n",
            "\n",
            "\t***** Results: *****\n",
            "\n",
            "\tC:98.2%[S:34.3%,D:63.9%],F:0.5%,M:1.4%,n:7934\t   \n",
            "\t7789\tComplete BUSCOs (C)\t\t\t   \n",
            "\t2720\tComplete and single-copy BUSCOs (S)\t   \n",
            "\t5069\tComplete and duplicated BUSCOs (D)\t   \n",
            "\t37\tFragmented BUSCOs (F)\t\t\t   \n",
            "\t108\tMissing BUSCOs (M)\t\t\t   \n",
            "\t7934\tTotal BUSCO groups searched\t\t   \n",
            "\n",
            "Dependencies and versions:\n",
            "\thmmsearch: 3.4\n",
            "\n",
            "\n",
            "üéØ 7789\tComplete BUSCOs (C)\n",
            "============================================================\n",
            "\n",
            "üíæ Saving to Google Drive: BUSCO_Results/NbT2T.pep_BUSCOv6.0.0_solanales_odb12\n",
            "‚úÖ Results saved to: /content/drive/MyDrive/BUSCO_Results/NbT2T.pep_BUSCOv6.0.0_solanales_odb12\n",
            "\n",
            "üì¶ Creating downloadable archive...\n",
            "\n",
            "üéâ Analysis Complete!\n",
            "üìÅ Google Drive: BUSCO_Results/NbT2T.pep_BUSCOv6.0.0_solanales_odb12\n",
            "\n",
            "üì• Downloading: NbT2T.pep_BUSCOv6.0.0_solanales_odb12.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a0d3d453-1791-4b20-aeee-3281004fac24\", \"NbT2T.pep_BUSCOv6.0.0_solanales_odb12.zip\", 79564707)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Download complete!\n"
          ]
        }
      ],
      "source": [
        "# @title **Run BUSCO Analysis and Download Results** { display-mode: \"form\" }\n",
        "# @markdown Execute BUSCO analysis and download comprehensive results.\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "import shutil\n",
        "import re\n",
        "import psutil\n",
        "from datetime import datetime\n",
        "\n",
        "# Auto-detect available CPU cores\n",
        "available_cores = psutil.cpu_count(logical=True)\n",
        "cpu_threads = available_cores\n",
        "\n",
        "# Load proteome path to auto-populate output name\n",
        "try:\n",
        "    with open('/content/proteome_path.txt', 'r') as f:\n",
        "        proteome_path = f.read().strip()\n",
        "    proteome_basename = os.path.splitext(os.path.basename(proteome_path))[0]\n",
        "    default_name = re.sub(r'[^a-zA-Z0-9._-]', '_', proteome_basename)\n",
        "except:\n",
        "    default_name = \"my_proteome\"\n",
        "\n",
        "# @markdown ---\n",
        "output_name = \"\" # @param {type:\"string\"}\n",
        "# @markdown **Optional:** Leave empty to auto-name from your proteome file, or enter a custom name to override.\n",
        "# @markdown ---\n",
        "\n",
        "print(\"üöÄ Starting BUSCO Analysis\\n\")\n",
        "\n",
        "# Display detected CPU configuration with CORRECT runtime identification\n",
        "print(\"=\"*60)\n",
        "print(\"CPU CONFIGURATION\")\n",
        "print(\"=\"*60)\n",
        "print(f\"üñ•Ô∏è  Detected CPU threads: {cpu_threads}\")\n",
        "\n",
        "# Correct runtime detection based on actual thread counts\n",
        "if cpu_threads >= 40:\n",
        "    print(f\"‚úÖ TPU v6e-1 Runtime detected - EXCELLENT performance ({cpu_threads} threads)\")\n",
        "elif cpu_threads >= 20:\n",
        "    print(f\"‚úÖ TPU v5e-1 Runtime detected - EXCELLENT performance ({cpu_threads} threads)\")\n",
        "elif cpu_threads >= 8:\n",
        "    print(f\"‚úÖ Pro+ High-RAM Runtime detected - GOOD performance ({cpu_threads} threads)\")\n",
        "elif cpu_threads >= 4:\n",
        "    print(f\"‚ö†Ô∏è  Standard Runtime detected - MODERATE performance ({cpu_threads} threads)\")\n",
        "    print(f\"üí° TIP: Use TPU v5e-1 or v6e-1 runtime for 12-22x faster analysis\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è  Standard Runtime detected - SLOW performance ({cpu_threads} threads)\")\n",
        "    print(f\"üí° TIP: Use TPU v5e-1 (24 threads) or v6e-1 (44 threads) for much faster analysis\")\n",
        "    print(f\"   Runtime ‚Üí Change runtime type ‚Üí TPU v5e-1 or v6e-1\")\n",
        "\n",
        "print(f\"‚öôÔ∏è  BUSCO will use all {cpu_threads} threads (100% CPU utilization)\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# Use auto-detected name if box is empty, otherwise use user input\n",
        "if not output_name.strip():\n",
        "    output_name = default_name\n",
        "    print(f\"üìù Output name: {output_name} (auto-detected)\")\n",
        "else:\n",
        "    # Sanitize user input\n",
        "    output_name = re.sub(r'[^a-zA-Z0-9._-]', '_', output_name.strip())\n",
        "    print(f\"üìù Output name: {output_name} (custom)\")\n",
        "\n",
        "# Verify file exists\n",
        "if not os.path.exists(proteome_path):\n",
        "    print(f\"‚ùå Proteome file not found: {proteome_path}\")\n",
        "    raise FileNotFoundError(\"Please upload your proteome file first.\")\n",
        "\n",
        "# Get BUSCO version\n",
        "print(\"\\nüîç Detecting BUSCO version...\")\n",
        "version_cmd = \"mamba run -n busco busco --version 2>&1\"\n",
        "version_result = subprocess.run(version_cmd, shell=True, capture_output=True, text=True)\n",
        "busco_version = \"unknown\"\n",
        "for line in version_result.stdout.split('\\n'):\n",
        "    if 'BUSCO' in line and any(char.isdigit() for char in line):\n",
        "        version_match = re.search(r'(\\d+\\.\\d+\\.\\d+)', line)\n",
        "        if version_match:\n",
        "            busco_version = version_match.group(1)\n",
        "            break\n",
        "print(f\"‚úÖ BUSCO version: {busco_version}\\n\")\n",
        "\n",
        "# Clean FASTA headers in-place\n",
        "print(\"üßπ Cleaning FASTA headers...\")\n",
        "with open(proteome_path, 'r') as f:\n",
        "    lines = f.readlines()\n",
        "cleaned_count = 0\n",
        "with open(proteome_path, 'w') as f:\n",
        "    for line in lines:\n",
        "        if line.startswith('>'):\n",
        "            original = line\n",
        "            clean_header = re.sub(r'[/|:;,\\s\\(\\)\\[\\]\\{\\}].*', '', line.strip())\n",
        "            f.write(clean_header + '\\n')\n",
        "            if original != clean_header + '\\n':\n",
        "                cleaned_count += 1\n",
        "        else:\n",
        "            f.write(line)\n",
        "print(f\"‚úÖ {cleaned_count} headers cleaned\\n\")\n",
        "\n",
        "# Get lineage from previous cell\n",
        "lineage_file = '/content/busco_downloads/lineages'\n",
        "if not os.path.exists(lineage_file):\n",
        "    print(\"‚ùå Lineage dataset not found. Please run the 'Select Lineage' cell first.\")\n",
        "    raise FileNotFoundError(\"Please download a lineage dataset first.\")\n",
        "\n",
        "available_lineages = os.listdir(lineage_file)\n",
        "if not available_lineages:\n",
        "    print(\"‚ùå No lineage datasets found. Please run the 'Select Lineage' cell first.\")\n",
        "    raise FileNotFoundError(\"Please download a lineage dataset first.\")\n",
        "\n",
        "selected_lineage = available_lineages[0]\n",
        "\n",
        "# Construct final folder name: output_name_BUSCOvX.X.X_database\n",
        "drive_folder_name = f\"{output_name}_BUSCOv{busco_version}_{selected_lineage}\"\n",
        "print(f\"üìÅ Results will be saved as: {drive_folder_name}\\n\")\n",
        "\n",
        "# Count sequences for progress estimation\n",
        "seq_count = sum(1 for line in open(proteome_path) if line.startswith('>'))\n",
        "\n",
        "# Calculate estimated time based on ACTUAL CPU thread count\n",
        "if cpu_threads >= 40:  # TPU v6e-1\n",
        "    time_min = max(1, seq_count * 0.00015)\n",
        "    time_max = max(3, seq_count * 0.0008)\n",
        "elif cpu_threads >= 20:  # TPU v5e-1\n",
        "    time_min = max(1, seq_count * 0.0003)\n",
        "    time_max = max(5, seq_count * 0.001)\n",
        "elif cpu_threads >= 8:  # Pro+ High-RAM\n",
        "    time_min = max(2, seq_count * 0.002)\n",
        "    time_max = max(8, seq_count * 0.008)\n",
        "else:  # Standard 2-4 threads\n",
        "    time_min = max(5, seq_count * 0.01)\n",
        "    time_max = max(30, seq_count * 0.05)\n",
        "\n",
        "print(f\"üìä Analysis Configuration:\")\n",
        "print(f\"   Proteome: {os.path.basename(proteome_path)}\")\n",
        "print(f\"   Sequences: {seq_count:,}\")\n",
        "print(f\"   Lineage: {selected_lineage}\")\n",
        "print(f\"   CPU threads: {cpu_threads}\")\n",
        "print(f\"\\n‚è≥ Estimated time: {time_min:.0f}-{time_max:.0f} minutes\")\n",
        "print(f\"‚è∞ Started: {datetime.now().strftime('%H:%M:%S')}\\n\")\n",
        "\n",
        "# Create temp output directory\n",
        "temp_output = f\"/content/busco_temp_{output_name}\"\n",
        "os.makedirs(temp_output, exist_ok=True)\n",
        "\n",
        "# Build BUSCO command with mamba environment wrapper\n",
        "busco_cmd = f\"\"\"mamba run -n busco busco \\\n",
        "    -i {proteome_path} \\\n",
        "    -o busco_temp_{output_name} \\\n",
        "    -m protein \\\n",
        "    -l {selected_lineage} \\\n",
        "    -c {cpu_threads} \\\n",
        "    --offline \\\n",
        "    --download_path /content/busco_downloads \\\n",
        "    -f\"\"\"\n",
        "\n",
        "# Run BUSCO with real-time output and progress tracking\n",
        "print(\"=\"*60)\n",
        "print(f\"üìà BUSCO Progress (live output - using {cpu_threads} threads):\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "start_time = datetime.now()\n",
        "process = subprocess.Popen(\n",
        "    busco_cmd,\n",
        "    shell=True,\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.STDOUT,\n",
        "    universal_newlines=True,\n",
        "    bufsize=1\n",
        ")\n",
        "\n",
        "stage_markers = {\n",
        "    'Checking': 'üîç',\n",
        "    'Running': '‚öôÔ∏è',\n",
        "    'Hmmsearch': 'üî¨',\n",
        "    'Results': 'üìä'\n",
        "}\n",
        "\n",
        "for line in process.stdout:\n",
        "    for marker, emoji in stage_markers.items():\n",
        "        if marker in line:\n",
        "            line = f\"{emoji} {line}\"\n",
        "            break\n",
        "    print(line.rstrip())\n",
        "\n",
        "process.wait()\n",
        "elapsed = (datetime.now() - start_time).total_seconds() / 60\n",
        "print(\"=\"*60)\n",
        "print(f\"‚è±Ô∏è  Completed in {elapsed:.1f} minutes using {cpu_threads} CPU threads\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if process.returncode == 0:\n",
        "    print(\"\\n‚úÖ BUSCO Analysis Complete!\\n\")\n",
        "\n",
        "    # Find the actual results directory\n",
        "    busco_results_dir = f\"/content/busco_temp_{output_name}/run_{selected_lineage}\"\n",
        "\n",
        "    # Find and display summary\n",
        "    summary_file = f\"{busco_results_dir}/short_summary.txt\"\n",
        "    if not os.path.exists(summary_file):\n",
        "        summary_file = f\"/content/busco_temp_{output_name}/short_summary.specific.{selected_lineage}.busco_temp_{output_name}.txt\"\n",
        "\n",
        "    if os.path.exists(summary_file):\n",
        "        print(\"üìä BUSCO RESULTS SUMMARY:\")\n",
        "        print(\"=\"*60)\n",
        "        with open(summary_file, 'r') as f:\n",
        "            summary = f.read()\n",
        "            print(summary)\n",
        "\n",
        "            for line in summary.split('\\n'):\n",
        "                if 'Complete BUSCOs' in line:\n",
        "                    print(f\"\\nüéØ {line.strip()}\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "    # Copy results to Google Drive\n",
        "    print(f\"\\nüíæ Saving to Google Drive: BUSCO_Results/{drive_folder_name}\")\n",
        "    drive_base = \"/content/drive/MyDrive/BUSCO_Results\"\n",
        "    os.makedirs(drive_base, exist_ok=True)\n",
        "    drive_output = os.path.join(drive_base, drive_folder_name)\n",
        "\n",
        "    try:\n",
        "        if os.path.exists(busco_results_dir):\n",
        "            shutil.copytree(busco_results_dir, drive_output)\n",
        "            print(f\"‚úÖ Results saved to: {drive_output}\")\n",
        "        else:\n",
        "            shutil.copytree(f\"/content/busco_temp_{output_name}\", drive_output)\n",
        "            print(f\"‚úÖ Results saved to: {drive_output}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Could not save to Drive: {e}\")\n",
        "\n",
        "    # Create downloadable ZIP\n",
        "    print(\"\\nüì¶ Creating downloadable archive...\")\n",
        "    zip_basename = f\"{drive_folder_name}\"\n",
        "    if os.path.exists(busco_results_dir):\n",
        "        shutil.make_archive(f\"/content/{zip_basename}\", 'zip', busco_results_dir)\n",
        "    else:\n",
        "        shutil.make_archive(f\"/content/{zip_basename}\", 'zip', f\"/content/busco_temp_{output_name}\")\n",
        "\n",
        "    print(\"\\nüéâ Analysis Complete!\")\n",
        "    print(f\"üìÅ Google Drive: BUSCO_Results/{drive_folder_name}\")\n",
        "    print(f\"\\nüì• Downloading: {zip_basename}.zip\")\n",
        "\n",
        "    from google.colab import files\n",
        "    files.download(f\"/content/{zip_basename}.zip\")\n",
        "\n",
        "    print(f\"\\n‚úÖ Download complete!\")\n",
        "\n",
        "else:\n",
        "    print(\"\\n‚ùå BUSCO analysis failed. Please check the error messages above.\")\n",
        "    print(\"\\nCommon issues:\")\n",
        "    print(\"   ‚Ä¢ Invalid FASTA format\")\n",
        "    print(\"   ‚Ä¢ Incorrect lineage selection\")\n",
        "    print(\"   ‚Ä¢ Insufficient memory (try smaller proteome or restart runtime)\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V5E1",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMx8HMVYHcqLi7hgLYVI512",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}